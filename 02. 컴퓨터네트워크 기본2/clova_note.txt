새로운 노트
2025.02.13 목 오전 11:08 ・ 31분 24초
김성환


참석자 1 00:00
키면 네 켰습니다.

참석자 1 00:09
오늘은 녹음된 거 혹시 송아 님에게 공유해 줄 수 있나요?
오늘 거

참석자 2 00:14
네네 지금 켜가지고 근데 지금 킨 걸로 하겠습니다.

참석자 1 00:23
그러면 질문을 드리겠습니다.

참석자 1 00:28
애플리케이션이 이용 가능한 트랜스포트 서비스 4가지에 대해서 말씀을 해주세요.

참석자 2 00:42
어 잘 트랜스포트 서비스라는 게 트랜스포터 레이어에서 발생하는 서비스를 말씀하시는 건가요?
아니면 오플레이 캐스턴 단계에서 발생하는 사용 가능한 서비스 말씀하시는 걸까요?

참석자 1 00:59
애플리케이션이 트랜스포트 레이어에서 기대할 수 있는 서비스를 말하는 건데 이게 저도 문제를 만들면서 문구가 좀 애매할 수 있다는 생각이 들었는데 이게 제가 컴퓨터 네트워크 하향식 접근에서 좀 가져온 자료이기도 하고 이번에 나왔던 강의 자료에서 나왔던 네 가지에 대해서 언급된 게 있었거든요.
근데 이제 그게 예를 들자면 신뢰적 데이터 전송 보안 그리고 이제 이 두 가지가 더 있었는데 이 두 가지에 대해서 더 말씀해 주실 수 있나요?
혹시 기억나실까요?

참석자 2 01:47
제가 말씀드릴 수 있는 건 실내전 전송 보안 그리고 잘 모르겠습니다.
어렵네요.

참석자 2 02:04
이거 처음에 이해 자체를 제가 잘못한 것 같아요. 처음에 이해를 트랜스포트 레이어에서 이제 서비스가 뭐가 있는지를 여쭤보는 줄 알아서 TSP하고 utp를 대답하려고 했는데 그 트랜스포트 레이어에서 어떤 일을 하는지 약간 그 애플리케이션 단계에서 기대하는 걸 물어보신 거였나요?

참석자 1 02:30
맞아요. 저거 어 원래는 텍스트로 올리긴 했는데 오늘 면접 분위기에서 이제 말로 할 것 같아서 문제 내용이 좀 문제의 질문 자체가 좀 애매했다는 느낌도 들기는 하네요.
그래서 제가 먼저 말씀드리자면 신내적 이 네 가지에는 신뢰적 데이터 전송 처리량 시간 보안 이 네 가지를 갖고 있는데 저희 나왔던 강의 자료와 엮으면서 처리량을 뚫을 푸시고 시간은 타이밍입니다.

참석자 1 03:12
혹시 기억나실까요?

참석자 2 03:14
네 좀 기억이 납니다. 데이터 통합하고 스루풋 시크리티 그리고 타이밍 네

참석자 1 03:23
네 맞습니다. 그래서 제가 여기서 질문 더 드릴 거는 이 철이란 거 이 시간에 대해서 설명할 수 있으신가요?

참석자 2 03:39
처리량은 데이터의 양을 처리할 수 있는 토탈을 말하는 거고 타이밍 같은 경우는 지연 시간을 말하는 겁니다.
그래서 지연 시간은 높지만 슬로풋이 높거나 슬로풋이 낮지만 타이밍이 높을 수 있습니다.
이렇게 답변할 수 있을 것 같아요.

참석자 1 04:08
잘 말씀해 주신 것 같아요. 근데 거기에 약간 처리량에 설명하실 때 양 말씀하실 때 앞에 주어진 일정 시간 동안 처리할 수 있는 양 그러니까 주어진 시간 안에 어느 정도 처리할 수 있는지에 대해서 이게 수치화되는 게 처리량인 거잖아요.
그쵸 네 그래서 앞에 단위 시간이나 일정 시간이나 이런 얘기가 좀 붙었으면 더 좋았을 것 같아요.
좋습니다.

참석자 1 04:53
네 질문을 쥐어짜고 쥐어 짜서 이렇게 나온 건 이렇게 여기까지 질문이 나왔고 여기 사실 이게 문제가 된 게 마지막 강의쯤에 강의 마지막쯤에 중간쯤에 처리량과 시간에 대해서 거의 서로 비슷한 얘기가 아니냐라는 학생의 질문이 있었길래 교수님이 답변한 내용이 있더라고요.

참석자 2 05:23
그래서 네 질문 되게 좋았습니다. 이거 답변하기가 쉽지 않더라고요.

참석자 1 05:31
근데 제가 질문을 좀 너무 애매하기도 한 것 같아요.
이게 약간 DPT한테 매기면은 뭔가 말씀하셨던 TCP UDP 이게 하는 게 나올 수도 있을 것 같거든요.
이게 저는 이 컴퓨터 데트워크 아까 말씀드렸듯이 이 책에서 나온 내용을 좀 썼는데 약간 번역이 좀 껄끄럽지 않았나 약간 이런 생각도 들긴 하 제가 준비한 질문은 여기까지입니다.

참석자 2 06:03
감사합니다.

참석자 2 06:12
이제 다음으로 제가 할 것 같은데 질문을 뭘 드릴지 잘 모르겠네요.

참석자 2 06:26
그러면 성현 님한테 질문을 드릴게요. 넌 퍼시스턴트 HTTP와 퍼시턴트 HTTP의 장점과 단점을 각각 하나씩 말씀해 주세요.
장점은 없으면 말씀 안 하셔도 괜찮습니다.

참석자 1 06:49
일단 비지속 연결 HTTP의 장점은 TCP 커넥션의 점유율이 낮아져서 서버의 오버헤드가 덜 발생한다는 것이 장점일 것 같습니다.
그리고 지속 연결 HTTP는 커넥션을 점유할 수 있기에 반복적인 커넥션을 맺음으로써 발생하는 세렌드 실크의 이게 얼티티로 인해 걸리는 시간이 최소화되어서 더 빠르게 데이터를 전송받을 수 있다는 장점이 있을 것 같습니다.

참석자 2 07:43
네 꼬리 질문은 꼬리 질문을 하는 순간부터 다음 강의로 넘어가는 것 같아서 일단 여기서 멈추도록 하고요.
일단 말씀해 주신 건 좋은 것 같습니다. 잘 말씀해 주신 것 같아요.
그래서 일단 넌 퍼시스턴트 같은 경우는 TGP 커넥션에서 하나의 오브젝트만 이제 전송이 되고 만약에 멀티플 하게 보내고 싶으면 여러 개의 커넥션을 매장한다는 단점이 있죠.
그 반면에 이제 퍼시턴트 같은 경우는 클라이언트하고 서버 간에 하나의 TCP 커넥션만으로 여러 개의 오브젝트를 주고받을 수 있으니까 그런 장점이 있습니다.
그렇고요.

참석자 2 08:35
다음으로 네네 말씀해 주세요.

참석자 1 08:39
약간 궁금한 건데 제가 이렇게 대답하려 할 때 보면 키워드를 먼저 잡으려고 했고 그다음에 설명하려고 했는데 이게 약간 상황도 같이 설명했으면 좀 더 좋았으려나요?
약간 좀 상황 제시가 좀 부족했을까요?

참석자 2 08:57
상황 제시라고 하면

참석자 1 09:01
네 약간 여러 가지 데이터를 동시에 받아야 될 경우에는 비지속으로 지속형으로 키버 라이브로 이제 커넥션을 맺어놓고 필요한 페이지의 데이터를 렌더링하는 데 필요한 데이터들을 바로바로 받을 수 있다 이렇게 좀 상황이 좀 제시됐으면 더 좋았으려나요?

참석자 2 09:27
제가 생각을 했을 때 그쪽이 좀 더 나을 것 같긴 합니다.
왜냐하면 이제 그 두 가지의 차이는 어찌 보면 실생활에서 나오는 케이스가 분명히 있을 거고 그런 케이스를 바탕으로 답변하는 게 단순히 이렇게 외우는 것보다는 훨씬 더 신뢰감이 있을 것 같습니다.

참석자 2 09:57
네 다음으로 병찬 님한테 질문드리면

참석자 2 10:11
너무 어려운데 잠깐만요. 뭘 뭘 좋아하지 뭘 뭐가 있을까요?
남은 게

참석자 2 10:26
서버와 클라이언트는 같은 컴퓨터 내에서 물리적인 컴퓨터 내에서 존재가 가능한가에 대해서 답변해 주시면 됩니다.
단순히 ox로 답변해 주시고 그거를 애플리케이션 단계에서 소켓을 바탕으로 답변해 주시면 감사하겠습니다.

참석자 1 10:47
우선 서버와 클라이언트는 같은 컴퓨터 내에서 존재가 가능하고요.
이제 그때 이제 서버와 클라이언트 간에 통신할 때는 OS 단에서 시스템 콜로 존재하는 시스템 콜을 바탕으로 서버와 클라이언트가 통신할 수 있는 걸로 알고 있습니다.

참석자 2 11:22
그러면 서로 통신 네네

참석자 1 11:25
네네 그거 한번 말씀해 주세요.

참석자 2 11:30
그럼 서로 통신을 할 때 만약에 HTTP로 연결을 한다고 하면 상호 간에 점유하는 소켓에 대해서 서로 충돌이 발생하거나 그런 문제가 발생하지 않을까요?

참석자 1 11:51
그 부분은 잘 모르겠습니다.

참석자 2 11:57
네 제가 생각한 답변은 소켓에 대해서 서버와 클라이언트 같은 경우 HTTP로 연결을 했을 때 서버는 80 포트를 점유하고 있고 클라이언트는 80 포트를 제외한 다른 포트를 점유하고 있기 때문에 충돌날 일이 없다라는 게 제가 생각한 답이었습니다.
근데 만약에 충돌나는 케이스가 발생할 수도 있는데 그거는 이제 소켓의 포트를 이제 다 점유했을 때 다 점유를 했을 때 충돌이 발생할 수 있으나 그렇게 될 경우 자체가 드물기 때문에 없다고 판단해도 무방할 것 같습니다.

참석자 1 12:42
영상

참석자 2 12:47
근데 너무 뭐 낼 게 없네요.

참석자 1 12:53
맞아요. 이게 진짜 저도 이미 다 겹쳤어요.

참석자 1 13:07
빠르게 저도 질문하겠습니다. 성현 님한테 질문드릴게요.

참석자 1 13:23
퍼시스턴트 HTTP를 사용했을 때 퍼시스턴트 HTTP에 어떤 기법을 또 추가해서 전송 속도를 올릴 수 있을까요?

참석자 1 13:45
답변드리도록 하겠습니다.

참석자 1 13:51
제가 사용하는 방법은 우선 HTTP 2.0에서 사용하고 있는 스테이 방식 기법이 생각이 나는데요.
이 스트리머스 기법은 기존에 HTTP 1.1에서 진행하던 지속형 연결 그 기법에서 스트림이라는 개념이 추가를 해서 계산을 했는데요.

참석자 1 14:20
기존의 HTTV 1.1에서는 TCP 커넥션을 키볼 라이브로 한 번 연결하고 이 데이터 요청을 단결적이 아닌 진열적으로 요청하고 인정을 받는 형태였습니다.
근데 HTTP 2.0이 들어서 스트립 기법을 추가할 데이터를 요청하는 것을 병렬적으로 요청할 수 있게 하여 데이터를 좀 더 빠른 시간 안에 받을 수 있게 계산한 방식이 바로 스트링입니다.
그래서 이 설명하니까 제가 마무리를 잘 못했는데 개선시킬 수 있는 방법이라든지 이런 스크린 방식이 있을 것 같습니다.
만약에 HTTP 2.0이 지원이 안 되고 1.1을 사용했을 때는 어떤 방식을 통해서 속도를 올릴 수 있을까요?

참석자 1 15:30
이게 만약 서버의 장점 HTP 기법만 얘기하신 건가요?
아니면은 이게 캐싱이라는 개념도 넣을 수 있을까요?
데 캐칭 개념도 더 안 하셔도 되고 저는 지속 커넥션 상태일 때 기존에 2.0에서 말씀해 주셨던 것처럼 스트림을 통해서 연결을 하면은 이전에 보낸 요청에 대한 응답이 오지 않아도 또 요청을 보낼 수 있잖아요.
근데 2.0에서는 기본적으로 스트림이라는 개념이 있어서 가능한데 1.1에서도 그와 같은 방식으로 동작할 수 있게 하는 방법은 뭐가 있는지 여쭤봤습니다.

참석자 1 16:34
캐시 말고는 지금 생각난 게 딱히 없는

참석자 1 16:43
이거 내가 생각한 답은 파이프라인 기법 중에서 1.1에서도 이전에 대한 응답이 오기 전에 바로 다음 요청을 보내는 방식을 생각했습니다.

참석자 1 17:19
파이프 라인이 키워드로 문제를 들었으면 좋겠어요.

참석자 1 17:34
다음 성아 님한테 질문드려도 될까요? 네

참석자 1 17:43
네트워크 성능 측정할 때 스로풋이랑 릴레이 두 가지 측정 방식이 있는데 이제 어떤 것을 우선적으로 고려해야 될까요?
성능 측정할 때 트로포이랑 딜레이션을

참석자 2 18:01
제가 생각한 답은 스루풋입니다. 스루풋에 대해서 설명드리면 만약에 100메가바이트에 대한 데이터를 상대방한테 전송한다고 하면 딜레이에 대해서 각각의 데이터 각각의 패킷이 딜레이 된 시간은 어 패킷 플러스 1만큼만 소요됩니다.
하지만 그 패킷이 전송되는 시간인 스루풋 같은 경우는 패킷의 양에 따라 가지고 달라지기 때문에 스루풋에 대해 먼저 늘린 다음 딜레이를 줄여야 하는 게 맞습니다.

참석자 1 18:40
만약에 실시간 서비스 같은 경우에서도 스루풋이 더 우선적으로 고려해야 될 사항일까?

참석자 2 18:47
실시간 서비스 중 어떤 서비스에 따라서 달라질 것 같은데 만약에 VOIP 같은 이제 음성을 바탕으로 하는 서비스라면 딜레이를 먼저 줄여야 하는 게 맞을 것 같고요.
두 번째로 만약에 동영상 서비스 같은 큰 데이터를 중요시하는 서비스 같은 경우는 슬로프스를 늘리는 게 맞을 것 같습니다.
이건 서비스의 특성에 따라 데이터의 용량에 따라서 달라지는 문제일 것 같습니다.

참석자 1 19:19
답변 잘해 주신 것 같아요. 감사합니다. 이거 질문 의도에 의도가 그냥 어떤 게 더 중요하다보다는 이제 서비스 특성에 따라서 스로풋이 중요할 수도 있고 딜레이가 더 중요할 수도 있는데 제가 물어봤을 때 이제 동영상 서비스 같은 경우는 트러플이 더 중요할 것 같고 아니면 화상 회의나 아니면 음성 서비스 같은 경우에서는 딜레이가 더 중요할 것 같다 이렇게 말씀해 주셔서 답변 잘하신 것 같습니다.
감사합니다.

참석자 1 20:05
그러면 딜레이를 최적화하려면 어떤 방법을 쓸 수 있을까요?

참석자 2 20:19
이거는 PPT에 나오진 않아서 제가 생각한 답변에 대해서 말씀드리면 각각의 이제 라우터마다의 CPU 성능을 높이는 방법이 첫 번째로 있을 것 같고요.
두 번째로 라우터 간에 이제 호바이 홈으로 연결되는 그 라우팅 경로를 최적화하는 방법이 있을 것 같습니다.
근데 그거 제외하고는 저도 지금 생각나는 게 없네요.

참석자 1 20:50
잘 답변하신 것 같아요. 이제 최적화하기 위해서 말씀하신 대로 라우팅 라우터 어드레스 최적화하는 방법이 있을 것 같고 그리고 GPT한테 물어봤을 때는 CDN 활용 서버의 지리적 분산 이렇게 나오는

참석자 2 21:17
와 이거 답변 못 하겠는데요.

참석자 1 21:23
근데 답변 잘하신 것 같아요. 버드 뭐까지입니다.

참석자 1 21:34
제가 어제 CS 면접 봤거든요. 네 근데 거기서 면접 보시는 분이 CS 과제가 HTTP 분석기를 구현하는 거였단 말이에요.
그래서 마침 저희가 HTTP 완벽하게 책을 다 봤잖아요.
그쵸. 근데 책에서 있는 내용을 정말 많이 나왔는데 이게 시간이 지나니까 까먹기도 하고 그리고 말로 설명하니까 잘 안 되더라고요.

참석자 1 22:19
그래서 이 방식 좋은 것 같아요.

참석자 2 22:22
저도 확실히 말이 더 나은 것 같아요. 글로 쓰는 것도 좋긴 한데 말로 하면은 생각이 정리되는 것도 있고 기억이 되게 잘 남는 것 같습니다.

참석자 1 22:39
그리고 어제 질문받았을 때 그냥 꼬리 질문이 엄청 나요.
제가 질문하는 거는 서버가 포트 포트를 최대 몇 개 가지고 있는지 물어보셨고 그리고 최대 포트 번호는 몇 번인지 물어보셨고

참석자 1 23:09
네 그 코트 번호를 어떻게 할당하는지 물어보셨고 이렇게 쭉쭉쭉 물어보시더라고요.
근데 대답을 잘 못했어요.

참석자 2 23:19
에반인데

참석자 1 23:24
방금 제가 대답한 것 못했는데요. 그죠? 저도 만 개 이렇게 왜 만 개를 생각하시느라 9999까지 있어서 이렇게 이렇게 말했다가 아니다.
하

참석자 2 23:42
그 개수가 2에 16승 마이너스 1개까지 있고요.
볼트가 포트 번호 할당되는 건 그냥 순차적으로 할당됐던 걸로 기억나는데 모르겠네요.

참석자 1 23:58
네 말씀해 주시기를 이게 16승 마이너스 이게 6만 5천 몇 개더라고요 코트 보면 6만 5천 몇 번까지 있고 실제로 사용하는 거는 3만 번대 이상부터 실제로 사용하고 포트 번호 할당을 그 사이에서 랜덤으로 한다고 하더라고요.

참석자 2 24:19
랜덤으로

참석자 1 24:20
네 그래서 질문 나왔던 게 저희 TC HTTP 완벽 가이드에서 TCP 연결 관련돼서 나왔잖아요.
네 네 거기서 연결 끊을 때 이제 연결 끊고 일정 시간 동안 해당 포트는 사용하지 않는 타임메이트를 가지잖아요.
네 네 그래서 여기서 말 왜 그 얘기가 나왔냐면은 리소스 요청할 때 병렬적으로 요청하면은 만약에 클라이언트 청회가 개 클라이언트 청개가 각각 천 개의 요청을 병렬적으로 요청하면은 TCP 커넥션으로 기본적으로 연결하게 되는데 연결이 끝나고 타임 웨이트 시간 동안 포트를 정리하고 있으니까 포트 번호를 모든 포트를 다 쓰게 되면은 연결을 못하잖아요.
네 그 얘기하면서 이제 포트 번호가 몇 개까지 있는지 포트는 어떻게 할당되는지 그리고 격렬 요청 보낼 때 어떻게 보내야 되는지 이렇게 쭉쭉쭉 물어보셨어요.

참석자 2 25:44
혹시 모의 면접 CS 질문하신 분이 누구신지 누구신가요?

참석자 1 25:53
성함이 기억 안 나는데 한 분 한 번 저희 멤버십 프로젝트 시작할 때 그때 여러 분 오셨잖아요.
태훈 님이랑 막 그런 시니어 분들이 오셨잖아요. 그때 그 시니어 분들 중 한 분이셨어요.

참석자 2 26:15
그러면 진짜 면접에서도 그렇게 물어본다는 거겠네요 진짜

참석자 1 26:23
네 맞아 본인 면접할 때는 그렇게 물어본다 해서 그렇게 물어보면은 보통 주니어들은 약간 CS 면접 그런 발비 같은 거 있잖아요.
좀 자주 나오는 질문 같은 것들을 모아둔 게 있잖아요.
주니어들은 그 부분에 대해서 대답을 잘하는데 이제 거기서 이제 계속 꼬치꼬치 캐물으면 그 뒤부터는 대답을 잘 못한다고 하더라고요.

참석자 2 27:04
그러면 얇고 넓게 파도 안 되고 깊고 넓게 파한다는 거 아닌가요?
이거

참석자 1 27:13
네 그래서 저도 진짜 깜짝 놀랐어요. 노드js는 HTTP 1.1부터 지속 커넥션을 기본으로 가시잖아요.

참석자 2 27:23
아 네

참석자 1 27:24
근데 노드 제이스는 이걸 꺼놓는다고 하더라고 키버 라이브 옵션을 꺼놓고 쓴다고 하더라고요.
기본적으로 이것도 처음 알아가지고

참석자 2 27:37
그러면 그 이유가 뭐 싱글 스레드라서 그런 건가요?

참석자 1 27:43
저도 모르

참석자 1 27:53
진짜 세더라고요. 저희 지금이라도 연습하니까 괜찮을 것 같아요.
저는 약간 초반에 약간 꼬리질이 나왔는데 좋았던 것 같아요.
그런 거 많이 하면은 뭔가 늘지 않을까요? 되게 그럴 것 같아요.
그리고 과제 테스트도 문제 한번 보셨나요? 정현 님 한번 보셨죠?
문제 CS 문제요? 네 네네 이것도 구현할 때 본인이 어떻게 구현 본인이라면 어떻게 구현했을지 이렇게 말씀해 주시는데 일단 그 확장성을 엄청 고려하시더라고요.
이런 과제 테스트 볼 때 그래서 과제 테스트에서 캐싱 관련된 기능 구현했었는데 문제 조건에서 캐싱은 lr 캐싱을 제외하고 다른 캐싱 방법을 써라 이렇게 나왔는데 저는 그냥 냅둬서 캐스팅 해버렸거든요.
진짜 단순하게. 근데 그렇게 하기보다는 본인이라면은 캐시 인터페이스를 따로 만들어서 어떤 캐싱 기법이든 이렇게 갈아 끼울 수 있게 하는 방법이 더 좋아 보인다고 말씀해 주셨더라고 그래서

참석자 1 29:44
느꼈습니다. 힘들고

참석자 1 29:54
약간 자유롭게 설계해라라고 하는 얘기는 사실상 자유롭게 언제든지 바뀔 수 있는 부분이니까 확장성 있게 인터페이스 쓰라라고 해석하는 게 좋은 것 같네요.
애매하게 나온 요구 사항에 대해서는 좀 열어두고 생각을 하라고 하시더라고요.

참석자 1 30:44
예 고생하시죠 네 고생하셨습니다.

참석자 2 30:50
네 수고하셨습니다. 그리고 클로바노트 같은 경우는 이거 긁어 가지고 오늘 2장 했잖아요.
2장 쪽에 추가하도록 하겠습니다.

참석자 1 31:04
감사합니다. 감사합니다. 수고하셨습니다.

참석자 2 31:14
고맙습니다.


clovanote.naver.com